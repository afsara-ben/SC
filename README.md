# Leveraging cache to enable SLU on tiny devices

This repository contains the source code for the paper titled "Leveraging cache to enable SLU on tiny devices" by authors - Afsara Benazir (co-author), Zhiming Xu (co-author), Felix Xiaozhu Lin 

## Dependencies

## Training

## Inference

## Acknowlegment
This work is inspired by the following end to end SLU project by Lugosch et. al.
* [end-to-end-SLU](https://github.com/lorenlugosch/end-to-end-SLU/tree/master): "Speech Model Pre-training for End-to-End Spoken Language Understanding"


If you find our paper useful, you can cite us:
```bibtex
@article{benazir2023leveraging,
  title={Leveraging cache to enable SLU on tiny devices},
  author={Benazir, Afsara and Xu, Zhiming and Lin, Felix Xiaozhu},
  journal={arXiv preprint arXiv:2311.18188},
  year={2023}
}
```
